DATASETS_AVAILABLE = [{"name": "Disaster Tweets Dataset",
                       "description": """
                                        The HumAID Twitter dataset consists of several thousands of manually annotated 
                                        tweets that has been collected during 19 major natural disaster events 
                                        including earthquakes, hurricanes, wildfires, and floods, which happened 
                                        from 2016 to 2019 across different parts of the World. The annotations in 
                                        the provided datasets consists of following humanitarian categories. The 
                                        dataset consists only english tweets and it is the largest dataset for 
                                        crisis informatics so far.
                                      """,
                       "url": "https://crisisnlp.qcri.org/humaid_dataset.html#"},
                      {"name": "Dummy Dataset 1", "description": "This is a placeholder for a demo dataset",
                       "url": "dummy_url_1"},
                      {"name": "Dummy Dataset 2", "description": "This is a placeholder for the another dataset",
                       "url": "dummy_url_2"}]

TEXTS_LIMIT = 100000
TABLE_LIMIT = 50
MAX_FEATURES = 200
KEEP_ORIGINAL = True
GROUP_1_EXCLUDE_ALREADY_LABELED = True
GROUP_2_EXCLUDE_ALREADY_LABELED = True
RND_STATE = 2584
PREDICTIONS_PROBABILITY = 0.85
PREDICTIONS_VERBOSE = False
SIMILAR_TEXT_VERBOSE = False
FIT_CLASSIFIER_VERBOSE = False
GROUP_3_KEEP_TOP = 50
FIRST_LABELING_FLAG = True

GROUP_1_KEEP_TOP = [10]
PREDICTIONS_NUMBER = [50]
TOTAL_SUMMARY = []
LABEL_SUMMARY = []
RECOMMENDATIONS_SUMMARY = []
OVERALL_QUALITY_SCORE = ["0.0%"]
TEXTS_LIST_LABELED = []
TEXTS_GROUP_1 = []
TEXTS_GROUP_2 = []
TEXTS_GROUP_3 = []
CLASSIFIER_LIST = []
SEARCH_MESSAGE = []
SEARCH_RESULT_LENGTH = [0]
TEXTS_LIST = []
TEXTS_LIST_FULL = []
TEXTS_LIST_LIST = []
TEXTS_LIST_LIST_FULL = []
TOTAL_PAGES_FULL = []
ADJ_TEXT_IDS = []
TOTAL_PAGES = []
VECTORIZED_CORPUS = []
Y_CLASSES = []
SHUFFLE_BY = []
CONFIRM_LABEL_ALL_TEXTS_COUNTS = [0]
NUMBER_UNLABELED_TEXTS = []
CLICK_LOG = []
VALUE_LOG = []
